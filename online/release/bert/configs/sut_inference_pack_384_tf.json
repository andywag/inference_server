{
    "task": "SQUAD",
    "encoder_start_ipu": 0,
    "layers_per_ipu": [12,12],
    "num_layers": 24,
    "vocab_length":30522,
    "hidden_size": 1024,
    "attention_heads": 16,
    "sequence_length": 384,
    "popart_dtype": "FLOAT16",
    "no_dropout": true,
    "stochastic_rounding": false,
    "batches_per_step": 256,
    "micro_batch_size": 10,
    "global_batch_size": 10,
    "split_qkv": true,
    "enable_half_partials": true,
    "tf_checkpoint": "/localdata/andyw/projects/public_examples/applications/inference/bert/run/build/data/bert_tf_v1_1_large_fp32_384_v2/model.ckpt-5474",
    "engine_cache": "__squad_tf",
    "inference": true,
    "max_copy_merge_size": -1,
    "available_memory_proportion": [0.445],
    "execution_mode": "PIPELINE",
    "use_packed_sequence_format": true,
    "attention_bias":true
}